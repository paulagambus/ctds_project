{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation Tools for Data Science - Group 6\n",
    "\n",
    "**Group members:**\n",
    "- Raquel Chaves Martinez - s243297\n",
    "- Paula Gambus i Moreno - s233219\n",
    "- Angel Paisan Garcia - s232793\n",
    "- Alba Pi Mas - s243280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import functions as f\n",
    "\n",
    "import string\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result of the merge of the datasets and calculation of the sentiment can be found in *main_complete.csv*. We recommend not rerunning the code used to generating the file because the computations involved are highly resource-intensive, resulting in long execution times.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we open all the datasets that we are going to get information from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = pd.read_csv('data/netflix.csv')\n",
    "amazon = pd.read_csv('data/amazon.csv')\n",
    "hulu = pd.read_csv('data/hulu.csv')\n",
    "apple = pd.read_csv('data/apple.csv')\n",
    "hbo = pd.read_csv('data/hbo.csv')\n",
    "\n",
    "main = pd.read_csv('data/TMDB_all_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to do movie recommendation, we remove all the entries that are not classified as movies in the platform datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing shows\n",
      "(20106, 8)\n",
      "(66905, 8)\n",
      "(9753, 8)\n",
      "(17648, 8)\n",
      "(7017, 8)\n",
      "After removing shows\n",
      "(15499, 8)\n",
      "(58559, 8)\n",
      "(5915, 8)\n",
      "(13598, 8)\n",
      "(3653, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Before removing shows')\n",
    "print(netflix.shape)\n",
    "print(amazon.shape)\n",
    "print(hulu.shape)\n",
    "print(apple.shape)\n",
    "print(hbo.shape)\n",
    "\n",
    "netflix = f.remove_tv_show(netflix)\n",
    "apple = f.remove_tv_show(apple)\n",
    "hulu = f.remove_tv_show(hulu)\n",
    "amazon = f.remove_tv_show(amazon)\n",
    "hbo = f.remove_tv_show(hbo)\n",
    "\n",
    "#dimension of the dataset\n",
    "print('After removing shows')\n",
    "print(netflix.shape)\n",
    "print(amazon.shape)\n",
    "print(hulu.shape)\n",
    "print(apple.shape)\n",
    "print(hbo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the auxiliar datasets clean, we can merge it with the main dataset. To do it, we have built a function that can be found in *function.py* . This function takes the platform dataset and the main dataset and adds a new binary column where the 0 indicates that the movie is not in the platform and the 1 represents that the movie is in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_netflix = f.platform_column(main, netflix, 'Netflix')\n",
    "main_net_ama = f.platform_column(main_netflix, amazon, 'Amazon')\n",
    "main_net_ama_hulu = f.platform_column(main_net_ama, hulu, 'Hulu')\n",
    "main_net_ama_hulu_apple = f.platform_column(main_net_ama_hulu, apple, 'Apple')\n",
    "main_complete = f.platform_column(main_net_ama_hulu_apple, hbo, 'HBO')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the amount of movies that we have in each platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies in Netflix: 36998.0\n",
      "Movies in Amazon prime: 108669.0\n",
      "Movies in Hulu: 15330.0\n",
      "Movies in Apple TV: 32572.0\n",
      "Movies in HBO Max: 10606.0\n"
     ]
    }
   ],
   "source": [
    "netflix_count = f.count_movies(main_complete, 'Netflix')\n",
    "print('Movies in Netflix:', netflix_count)\n",
    "amazon_count = f.count_movies(main_complete, 'Amazon')\n",
    "print('Movies in Amazon prime:', amazon_count)\n",
    "hulu_count = f.count_movies(main_complete, 'Hulu')\n",
    "print('Movies in Hulu:', hulu_count)\n",
    "apple_count = f.count_movies(main_complete, 'Apple')\n",
    "print('Movies in Apple TV:', apple_count)\n",
    "hbo_count = f.count_movies(main_complete, 'HBO')\n",
    "print('Movies in HBO Max:', hbo_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the information in the same dataframe, we can start applying methods. First, we will calculate the sentiment of the overview of the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will do some exploration of the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          After the coal mine he works at closes and his...\n",
       "1          Nikander, a rubbish collector and would-be ent...\n",
       "2          It's Ted the Bellhop's first night on the job....\n",
       "3          Four young friends, while taking a shortcut en...\n",
       "4          Timo Novotny labels his new project an experim...\n",
       "                                 ...                        \n",
       "1009834    “Hommage à Beksinski” is a short film commissi...\n",
       "1009835                                                  NaN\n",
       "1009836                                                  NaN\n",
       "1009837                                                  NaN\n",
       "1009838                                                  NaN\n",
       "Name: overview, Length: 1009839, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_complete['overview']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, there are some missing values in the overview (description of the movie). When we calculate the sentiment, the movies that don't have an overview will be assigned Nan and not 0, because a sentiment of 0 denotes sadness (the lower the score, the sadder is the description/movie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a sentiment function that takes a list of tokens and calculates the sentiment based on the LabMT wordlist. This function is called by a fucntion named *preprocess_and_analyze_sentiment*, which takes the text and returns the sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation_table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_complete['sentiment'] = main_complete['overview'].apply(f.preprocess_and_analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the main_complete dataset\n",
    "#main_complete.to_csv('data/main_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the dataset to calculate similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merging the movies dataset with the platforms dataset and adding the sentiment score columnd we saved the resulting dataset ('main_complete') to avoid generating it every time. Here, we load the dataset and continue working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comput_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
